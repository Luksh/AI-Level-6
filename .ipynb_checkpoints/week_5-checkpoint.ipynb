{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38786e3d-3eed-4d29-8438-6872d31232b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text: \n",
      "This is a simple example of text preprocessing. It involves cleaning and organizing raw text data into a format suitable for analysis.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\LENOVO\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\LENOVO\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\LENOVO\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\LENOVO\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download(\"punkt_tab\")\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "\n",
    "# Sample text\n",
    "text = \"This is a simple example of text preprocessing. It involves cleaning and organizing raw text data into a format suitable for analysis.\"\n",
    "\n",
    "print(\"Original Text: \")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e256c58-4083-413f-8c19-60b87083e6c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lower case Text: \n",
      "this is a simple example of text preprocessing. it involves cleaning and organizing raw text data into a format suitable for analysis.\n"
     ]
    }
   ],
   "source": [
    "# Convert to lowercase\n",
    "text = text.lower()\n",
    "\n",
    "print(\"lower case Text: \")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c57c854-e3b4-4790-9474-ae0d272b60b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed punctuation : \n",
      "this is a simple example of text preprocessing it involves cleaning and organizing raw text data into a format suitable for analysis\n"
     ]
    }
   ],
   "source": [
    "# Remove punctuation\n",
    "text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "\n",
    "print(\"Removed punctuation : \")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "318ca553-51ab-4e74-a543-90a10fa42c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tokens: \n",
      "['this', 'is', 'a', 'simple', 'example', 'of', 'text', 'preprocessing', 'it', 'involves', 'cleaning', 'and', 'organizing', 'raw', 'text', 'data', 'into', 'a', 'format', 'suitable', 'for', 'analysis']\n"
     ]
    }
   ],
   "source": [
    "# Tokenization\n",
    "tokens = word_tokenize(text)\n",
    "\n",
    "print(\"All tokens: \")\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3dbcaa8d-6ec3-414c-855e-3e6c7ed5e4be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After Text Preprocessing: \n",
      "['simple', 'example', 'text', 'preprocessing', 'involves', 'cleaning', 'organizing', 'raw', 'text', 'data', 'format', 'suitable', 'analysis']\n"
     ]
    }
   ],
   "source": [
    "# Removing stopwords\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "filtered_tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "print(\"\\nAfter Text Preprocessing: \")\n",
    "print(filtered_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "836a9e27-a443-4386-9599-6587d1fff7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Today I have no words. They went away to rest. Maybe they need time; maybe I do too.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43872d84-42a4-4f62-acff-722fb5924873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lower case Text: \n",
      "today i have no words. they went away to rest. maybe they need time; maybe i do too.\n"
     ]
    }
   ],
   "source": [
    "text = text.lower()\n",
    "\n",
    "print(\"lower case Text: \")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "481f63af-f897-43e8-8ebb-ef48bd2938d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed punctuation : \n",
      "today i have no words they went away to rest maybe they need time maybe i do too\n"
     ]
    }
   ],
   "source": [
    "text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "print(\"Removed punctuation : \")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dee4f64f-0c88-45f7-b4eb-89935b91eaa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tokens: \n",
      "['today', 'i', 'have', 'no', 'words', 'they', 'went', 'away', 'to', 'rest', 'maybe', 'they', 'need', 'time', 'maybe', 'i', 'do', 'too']\n"
     ]
    }
   ],
   "source": [
    "tokens = word_tokenize(text)\n",
    "print(\"All tokens: \")\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "52ef07af-9786-498a-89f1-6a199ba4e12c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After Text Preprocessing: \n",
      "['today', 'words', 'went', 'away', 'rest', 'maybe', 'need', 'time', 'maybe']\n"
     ]
    }
   ],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))\n",
    "filtered_tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "print(\"\\nAfter Text Preprocessing: \")\n",
    "print(filtered_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bcc5ec26-8c50-433d-993c-1043220b6fdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chelsea Football Club stands as a titan of English and European football, a club forged in ambition, resilience, and an unrelenting pursuit of greatness. Since its founding in 1905, Chelsea has risen to the pinnacle of world football, capturing multiple Premier League titles, FA Cups, and European trophies, including two UEFA Champions League triumphs that solidified its status among the elite. Known for its bold attacking play, iconic players, and visionary leadership, Chelsea thrives on a winning mentality that defines its blue-blooded legacy. From the roaring atmosphere of Stamford Bridge to the clubâ€™s global fanbase, Chelsea is more than just a football teamâ€”it is a symbol of pride, passion, and relentless excellence, forever etching its name in the annals of football history.\n"
     ]
    }
   ],
   "source": [
    "with open(\"Chelsea.txt\", \"r\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a59f0aee-7019-4fe6-aed5-777335183910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lower case Text: \n",
      "chelsea football club stands as a titan of english and european football, a club forged in ambition, resilience, and an unrelenting pursuit of greatness. since its founding in 1905, chelsea has risen to the pinnacle of world football, capturing multiple premier league titles, fa cups, and european trophies, including two uefa champions league triumphs that solidified its status among the elite. known for its bold attacking play, iconic players, and visionary leadership, chelsea thrives on a winning mentality that defines its blue-blooded legacy. from the roaring atmosphere of stamford bridge to the clubâ€™s global fanbase, chelsea is more than just a football teamâ€”it is a symbol of pride, passion, and relentless excellence, forever etching its name in the annals of football history.\n"
     ]
    }
   ],
   "source": [
    "text = text.lower()\n",
    "print(\"lower case Text: \")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "28ecc744-363b-4cdc-93f3-40b3a186398c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed punctuation : \n",
      "chelsea football club stands as a titan of english and european football a club forged in ambition resilience and an unrelenting pursuit of greatness since its founding in 1905 chelsea has risen to the pinnacle of world football capturing multiple premier league titles fa cups and european trophies including two uefa champions league triumphs that solidified its status among the elite known for its bold attacking play iconic players and visionary leadership chelsea thrives on a winning mentality that defines its blueblooded legacy from the roaring atmosphere of stamford bridge to the clubâ€™s global fanbase chelsea is more than just a football teamâ€”it is a symbol of pride passion and relentless excellence forever etching its name in the annals of football history\n"
     ]
    }
   ],
   "source": [
    "text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "print(\"Removed punctuation : \")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "40083bbe-15eb-4335-a8f4-7f7e324633db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tokens: \n",
      "['chelsea', 'football', 'club', 'stands', 'as', 'a', 'titan', 'of', 'english', 'and', 'european', 'football', 'a', 'club', 'forged', 'in', 'ambition', 'resilience', 'and', 'an', 'unrelenting', 'pursuit', 'of', 'greatness', 'since', 'its', 'founding', 'in', '1905', 'chelsea', 'has', 'risen', 'to', 'the', 'pinnacle', 'of', 'world', 'football', 'capturing', 'multiple', 'premier', 'league', 'titles', 'fa', 'cups', 'and', 'european', 'trophies', 'including', 'two', 'uefa', 'champions', 'league', 'triumphs', 'that', 'solidified', 'its', 'status', 'among', 'the', 'elite', 'known', 'for', 'its', 'bold', 'attacking', 'play', 'iconic', 'players', 'and', 'visionary', 'leadership', 'chelsea', 'thrives', 'on', 'a', 'winning', 'mentality', 'that', 'defines', 'its', 'blueblooded', 'legacy', 'from', 'the', 'roaring', 'atmosphere', 'of', 'stamford', 'bridge', 'to', 'the', 'clubâ€™s', 'global', 'fanbase', 'chelsea', 'is', 'more', 'than', 'just', 'a', 'football', 'teamâ€', '”', 'it', 'is', 'a', 'symbol', 'of', 'pride', 'passion', 'and', 'relentless', 'excellence', 'forever', 'etching', 'its', 'name', 'in', 'the', 'annals', 'of', 'football', 'history']\n"
     ]
    }
   ],
   "source": [
    "tokens = word_tokenize(text)\n",
    "print(\"All tokens: \")\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cade280f-fc6d-41ec-9ab7-4531ce0a18d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After Text Preprocessing: \n",
      "['chelsea', 'football', 'club', 'stands', 'titan', 'english', 'european', 'football', 'club', 'forged', 'ambition', 'resilience', 'unrelenting', 'pursuit', 'greatness', 'since', 'founding', '1905', 'chelsea', 'risen', 'pinnacle', 'world', 'football', 'capturing', 'multiple', 'premier', 'league', 'titles', 'fa', 'cups', 'european', 'trophies', 'including', 'two', 'uefa', 'champions', 'league', 'triumphs', 'solidified', 'status', 'among', 'elite', 'known', 'bold', 'attacking', 'play', 'iconic', 'players', 'visionary', 'leadership', 'chelsea', 'thrives', 'winning', 'mentality', 'defines', 'blueblooded', 'legacy', 'roaring', 'atmosphere', 'stamford', 'bridge', 'clubâ€™s', 'global', 'fanbase', 'chelsea', 'football', 'teamâ€', '”', 'symbol', 'pride', 'passion', 'relentless', 'excellence', 'forever', 'etching', 'name', 'annals', 'football', 'history']\n"
     ]
    }
   ],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))\n",
    "filtered_tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "print(\"\\nAfter Text Preprocessing: \")\n",
    "print(filtered_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f4afda5a-c175-4a36-b44e-e88922516d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: cats, Lemma: cat\n",
      "Word: cacti, Lemma: cactus\n",
      "Word: geese, Lemma: goose\n",
      "Word: rocks, Lemma: rock\n",
      "Word: python, Lemma: python\n",
      "Word: better, Lemma: better\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "words = [\"cats\", \"cacti\", \"geese\", \"rocks\", \"python\", \"better\"]\n",
    "\n",
    "for word in words:\n",
    "    print(f\"Word: {word}, Lemma: {lemmatizer.lemmatize(word)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4aa56e4e-f197-41ee-9404-0627ad933a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: chelsea, Lemma: chelsea\n",
      "Word: football, Lemma: football\n",
      "Word: club, Lemma: club\n",
      "Word: stands, Lemma: stand\n",
      "Word: titan, Lemma: titan\n",
      "Word: english, Lemma: english\n",
      "Word: european, Lemma: european\n",
      "Word: football, Lemma: football\n",
      "Word: club, Lemma: club\n",
      "Word: forged, Lemma: forged\n",
      "Word: ambition, Lemma: ambition\n",
      "Word: resilience, Lemma: resilience\n",
      "Word: unrelenting, Lemma: unrelenting\n",
      "Word: pursuit, Lemma: pursuit\n",
      "Word: greatness, Lemma: greatness\n",
      "Word: since, Lemma: since\n",
      "Word: founding, Lemma: founding\n",
      "Word: 1905, Lemma: 1905\n",
      "Word: chelsea, Lemma: chelsea\n",
      "Word: risen, Lemma: risen\n",
      "Word: pinnacle, Lemma: pinnacle\n",
      "Word: world, Lemma: world\n",
      "Word: football, Lemma: football\n",
      "Word: capturing, Lemma: capturing\n",
      "Word: multiple, Lemma: multiple\n",
      "Word: premier, Lemma: premier\n",
      "Word: league, Lemma: league\n",
      "Word: titles, Lemma: title\n",
      "Word: fa, Lemma: fa\n",
      "Word: cups, Lemma: cup\n",
      "Word: european, Lemma: european\n",
      "Word: trophies, Lemma: trophy\n",
      "Word: including, Lemma: including\n",
      "Word: two, Lemma: two\n",
      "Word: uefa, Lemma: uefa\n",
      "Word: champions, Lemma: champion\n",
      "Word: league, Lemma: league\n",
      "Word: triumphs, Lemma: triumph\n",
      "Word: solidified, Lemma: solidified\n",
      "Word: status, Lemma: status\n",
      "Word: among, Lemma: among\n",
      "Word: elite, Lemma: elite\n",
      "Word: known, Lemma: known\n",
      "Word: bold, Lemma: bold\n",
      "Word: attacking, Lemma: attacking\n",
      "Word: play, Lemma: play\n",
      "Word: iconic, Lemma: iconic\n",
      "Word: players, Lemma: player\n",
      "Word: visionary, Lemma: visionary\n",
      "Word: leadership, Lemma: leadership\n",
      "Word: chelsea, Lemma: chelsea\n",
      "Word: thrives, Lemma: thrives\n",
      "Word: winning, Lemma: winning\n",
      "Word: mentality, Lemma: mentality\n",
      "Word: defines, Lemma: defines\n",
      "Word: blueblooded, Lemma: blueblooded\n",
      "Word: legacy, Lemma: legacy\n",
      "Word: roaring, Lemma: roaring\n",
      "Word: atmosphere, Lemma: atmosphere\n",
      "Word: stamford, Lemma: stamford\n",
      "Word: bridge, Lemma: bridge\n",
      "Word: clubâ€™s, Lemma: clubâ€™s\n",
      "Word: global, Lemma: global\n",
      "Word: fanbase, Lemma: fanbase\n",
      "Word: chelsea, Lemma: chelsea\n",
      "Word: football, Lemma: football\n",
      "Word: teamâ€, Lemma: teamâ€\n",
      "Word: ”, Lemma: ”\n",
      "Word: symbol, Lemma: symbol\n",
      "Word: pride, Lemma: pride\n",
      "Word: passion, Lemma: passion\n",
      "Word: relentless, Lemma: relentless\n",
      "Word: excellence, Lemma: excellence\n",
      "Word: forever, Lemma: forever\n",
      "Word: etching, Lemma: etching\n",
      "Word: name, Lemma: name\n",
      "Word: annals, Lemma: annals\n",
      "Word: football, Lemma: football\n",
      "Word: history, Lemma: history\n"
     ]
    }
   ],
   "source": [
    "for word in filtered_tokens:\n",
    "    print(f\"Word: {word}, Lemma: {lemmatizer.lemmatize(word)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "65698719-4db0-4368-9cff-a9862a575222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello!\n",
      "This is an example of sentence segmentation.\n",
      "It demonstrates how sentence segmentation works using NLTK.\n",
      "Hope you find it helpful.\n"
     ]
    }
   ],
   "source": [
    "from nltk import sent_tokenize\n",
    "\n",
    "text = \"Hello! This is an example of sentence segmentation. It demonstrates how sentence segmentation works using NLTK. Hope you find it helpful.\"\n",
    "sentences = sent_tokenize(text)\n",
    "\n",
    "for sentence in sentences:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4f079e79-5a2c-44c9-8190-6c8621a246ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chelsea Football Club stands as a titan of English and European football, a club forged in ambition, resilience, and an unrelenting pursuit of greatness. Known for its bold attacking play, iconic players, and visionary leadership, Chelsea thrives on a winning mentality that defines its blue-blooded legacy.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\LENOVO\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\LENOVO\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Text summarizing script\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from collections import defaultdict\n",
    "import string\n",
    "\n",
    "# Ensure necessary NLTK data is downloaded\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "\n",
    "def summarize_text(file_path):\n",
    "    # Read the text from the file\n",
    "    with open(\n",
    "        file_path,\n",
    "        \"r\",\n",
    "    ) as f:\n",
    "        text = f.read()\n",
    "\n",
    "    # Step A: Tokenize sentences and words\n",
    "    sentences = sent_tokenize(text)\n",
    "    words = word_tokenize(text.lower())\n",
    "\n",
    "    # Step B: Remove stopwords and punctuation\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    words = [\n",
    "        word\n",
    "        for word in words\n",
    "        if word not in stop_words and word not in string.punctuation\n",
    "    ]\n",
    "\n",
    "    # Step C: Calculate word frequencies\n",
    "    word_frequencies = defaultdict(int)\n",
    "    for word in words:\n",
    "        word_frequencies[word] += 1\n",
    "\n",
    "    # Step D: Score sentences based on word frequencies (only considering sentences < 30 words)\n",
    "    sentence_scores = {}\n",
    "    for sentence in sentences:\n",
    "        word_count = len(word_tokenize(sentence))\n",
    "        if word_count < 30:\n",
    "            sentence_scores[sentence] = sum(\n",
    "                word_frequencies[word]\n",
    "                for word in word_tokenize(sentence.lower())\n",
    "                if word in word_frequencies\n",
    "            )\n",
    "\n",
    "    # Step E: Select the top 2 highest-scoring sentences\n",
    "    summary_sentences = sorted(sentence_scores, key=sentence_scores.get, reverse=True)[\n",
    "        :2\n",
    "    ]\n",
    "\n",
    "    # Step F: Combine them to create the final summary\n",
    "    summary = \" \".join(summary_sentences)\n",
    "    return summary\n",
    "\n",
    "\n",
    "file_path = \"Chelsea.txt\"\n",
    "print(summarize_text(file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0b0a84-753f-4729-9140-149714aaf38a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
